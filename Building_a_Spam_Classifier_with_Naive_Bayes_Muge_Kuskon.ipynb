{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Building_a_Spam_Classifier_with_Naive_Bayes_Muge_Kuskon.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Eol6efMMxIQV"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mugekuskon/BuildingSpamClassifier/blob/main/Building_a_Spam_Classifier_with_Naive_Bayes_Muge_Kuskon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZSMyoO-t-br"
      },
      "source": [
        "*Müge Kuşkon 25425*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYGLK0LinN86"
      },
      "source": [
        "# ***Naïve Bayes Implementation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1D13avqnnMmV"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "#Check if the training data is balanced or not. \n",
        "train_features = pd.read_csv('train-features.txt', sep=\" \", header=None)\n",
        "train_labels = pd.read_csv('train-labels.txt', sep=\" \", header=None)\n",
        "\n",
        "vocab = 2500\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DX0KjiPGqEGV",
        "outputId": "6d021eec-8750-42ae-f25b-b6db95b902a0"
      },
      "source": [
        "#Show the balance between class 1 and 0. \n",
        "#The result shows us that the training data is balanced. Half.\n",
        "train_labels.value_counts() #Both are 350.\n",
        "probOfspam = train_labels[0].value_counts()[1]/(len(train_labels))\n",
        "probOfnonspam =  1 - probOfspam\n",
        "\n",
        "print(\"Py=0 is \", probOfnonspam, \"\\nPy=1 is \", probOfspam)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Py=0 is  0.5 \n",
            "Py=1 is  0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5zspvS6rAvT"
      },
      "source": [
        " **Traning a Naive Bayes Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHExau3_qvTB"
      },
      "source": [
        "#Train it on the training data and test the classifier on the test data.\n",
        "#Report test accuracy and how many predictions were made.\n",
        "#MLE estimator should be used. When tie predict nonspam. \n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#print(train_labels[0]) #To check whether the mail belongs to a spam or not. \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukyRfihb0B-o"
      },
      "source": [
        "#Sum of each mail, each rows according to their index.\n",
        "sumForEachMail = [0]*700 #size of the email numbers.\n",
        "\n",
        "for x in range(700): #700.\n",
        "  for y in range(vocab):#all the vocabulary.\n",
        "     sumForEachMail[x] += int(train_features[y][x])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul42Huv9eFhQ"
      },
      "source": [
        "#Functions to be used:\n",
        "import math\n",
        "\n",
        "#TRAINING PART:\n",
        "\n",
        "def calculateNumofWords(sumForEachMail, train_labels):\n",
        "  numofSpam = 0\n",
        "  numofNonSpam = 0\n",
        "  for s in range(len(sumForEachMail)):\n",
        "    if train_labels[0][s] == 0:#nonspam\n",
        "      numofNonSpam += sumForEachMail[s]\n",
        "    if train_labels[0][s] == 1:#spam\n",
        "      numofSpam += sumForEachMail[s]\n",
        "  return numofSpam, numofNonSpam\n",
        "\n",
        "def occurences(vocab, train_features, train_labels, nonspam, spam):\n",
        "  for x in range(len(train_features)): #700.\n",
        "    for y in range(vocab):#all the vocabulary.\n",
        "      if train_labels[0][x] == 0: #belongs to the nonspam category\n",
        "        nonspam[y] += train_features[y][x] #increasing the according index of the word by its occurence.\n",
        "      if train_labels[0][x] == 1: #belongs to the spam category\n",
        "        spam[y] += train_features[y][x]  #increasing the according index of the word by its occurence.\n",
        "  return spam, nonspam\n",
        "\n",
        "def spamEstimator(spam, numofSpam, map, total): #map and total is used for additive smoothing.\n",
        "  spamEstimation=[]\n",
        "  for i in spam:\n",
        "    spamEstimation.append((i+map)/(numofSpam+total))\n",
        "  return spamEstimation\n",
        "\n",
        "def nonspamEstimator(nonspam, numofNonSpam, map, total): #map and total is used for additive smoothing.\n",
        "  nonspamEstimation=[]\n",
        "  for i in nonspam:\n",
        "    nonspamEstimation.append((i+map)/(numofNonSpam+total))\n",
        "  return nonspamEstimation\n",
        "\n",
        "#TESTING PART:\n",
        "\n",
        "def logCalculation(occ, estimation):\n",
        "  result = 0\n",
        "  if occ == 0 and estimation == 0:\n",
        "    result = 0\n",
        "  elif occ != 0 and estimation ==0:\n",
        "    result = float(-math.inf)\n",
        "  else:\n",
        "    result = occ*math.log(estimation)\n",
        "  return result\n",
        "\n",
        "def mailPredict(test_features, vocab, mailPrediction, nonspamEstimation, spamEstimation):\n",
        "\n",
        "  for i in range(len(test_features)):#260\n",
        "    class0 = 0 #keep the sum to compare later which class is more likely. \n",
        "    class1 = 0 #spam\n",
        "    for j in range(vocab):\n",
        "      class0 +=  logCalculation(test_features[j][i], nonspamEstimation[j]) #number of occurences times its likelihood to be nonspam.\n",
        "      class1 +=  logCalculation(test_features[j][i], spamEstimation[j])\n",
        "    class0 = logCalculation(1,probOfnonspam) + class0\n",
        "    class1 = logCalculation(1,probOfspam) + class1\n",
        "    if class0 < class1:\n",
        "      #prediction is spam.\n",
        "      mailPrediction.append(1)\n",
        "\n",
        "    else:\n",
        "      #more likely to become a nonspam.\n",
        "      mailPrediction.append(0)\n",
        " \n",
        "  return mailPrediction\n",
        "\n",
        "\n",
        "\n",
        "def accuracyCalculation(predict,test_labels):\n",
        "  correctLabel = 0\n",
        "  for p in range(len(predict)):\n",
        "    if predict[p] == test_labels[0][p]:\n",
        "      correctLabel += 1\n",
        "  return(correctLabel/len(test_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3jneSSp7Mzy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3162099-194d-40d3-8154-bb740e73456c"
      },
      "source": [
        "#Calculating number of words in spam and nonspam emails.\n",
        "\n",
        "numofSpam, numofNonSpam = calculateNumofWords(sumForEachMail, train_labels)\n",
        "\n",
        "#Number of words in each class\n",
        "print(\"Number of words in Spam:\", numofSpam, \"\\nNonSpam: \", numofNonSpam)\n",
        "\n",
        "#Keep the occurences of words in vocab for two of the classes.\n",
        "nonspam = [0]*2500\n",
        "spam = [0]*2500\n",
        "\n",
        "\n",
        "spam, nonspam = occurences(vocab, train_features, train_labels, nonspam, spam)     \n",
        "#print(spam)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in Spam: 91566 \n",
            "NonSpam:  61752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AABcx-9s_Xaf"
      },
      "source": [
        "#Last two parameters are zero since this is not the MAP estimation.\n",
        "spamEstimation = spamEstimator(spam, numofSpam, 0, 0) # (θj/y=1) Finding the likelihood of word being spam.\n",
        "nonspamEstimation = nonspamEstimator(nonspam, numofNonSpam, 0, 0) # (θj/y=0) Finding the likelihood of word being nonspam.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1de81LD-BHlh"
      },
      "source": [
        "**Testing Part:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4zl_eNiBLB_"
      },
      "source": [
        "\n",
        "test_features = pd.read_csv('test-features.txt', sep=\" \", header=None)\n",
        "test_labels = pd.read_csv('test-labels.txt', sep=\" \", header=None)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WABAq2C4W_HO"
      },
      "source": [
        "mailPrediction = [] #list where the predictions will be appended. (0 or 1).\n",
        "mailPrediction = mailPredict(test_features, vocab, mailPrediction, nonspamEstimation, spamEstimation )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WT6uyZVqv7Xm",
        "outputId": "48432ae3-fba1-4639-cc89-0e1e691f8a59"
      },
      "source": [
        "accuracy = accuracyCalculation(mailPrediction, test_labels )\n",
        "print(\"Accuracy of the model is: \", accuracy )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model is:  0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-r6jBTG-U2e"
      },
      "source": [
        "#Extending the classifier by using additive smoothing.\n",
        "spamEstimatorforMAP = spamEstimator(spam, numofSpam, 1, vocab) #the last two parameters are for the additive smoothing.\n",
        "nonspamEstimationforMAP = nonspamEstimator(nonspam, numofNonSpam, 1, vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwU9oi3e_wO_"
      },
      "source": [
        "mailPredictionforMAP = []\n",
        "mailPredictionforMAP = mailPredict(test_features, vocab, mailPredictionforMAP, nonspamEstimationforMAP, spamEstimatorforMAP )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkdDcQ5JV4SM",
        "outputId": "803b7771-0e3e-4ccc-e1dd-57fb6eab8937"
      },
      "source": [
        "accuracy = accuracyCalculation(mailPredictionforMAP, test_labels )\n",
        "print(\"Accuracy of the model after additive smoothing is: \", accuracy )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model after additive smoothing is:  0.9730769230769231\n"
          ]
        }
      ]
    }
  ]
}